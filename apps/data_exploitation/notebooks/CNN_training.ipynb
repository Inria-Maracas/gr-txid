{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 12:30:31.569599: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/tmp/ipykernel_35141/1126927599.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mglob\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m model\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m input_utils\n\u001b[1;32m      9\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m#Set to 0 to use the first GPU, 1 for the second, -1 to use ony the CPU\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "import os\n",
    "import glob\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" #Set to 0 to use the first GPU, 1 for the second, -1 to use ony the CPU\n",
    "os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\" # May help with execution speed\n",
    "# os.environ[\"TF_XLA_FLAGS\"] = \"tf_xla_auto_jit=2\"\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = \"/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/\"\n",
    "# data_folder = \"/app/local_home/cmorin/Tx-Id/datasets/MultiRx/20230525_16h50/\"\n",
    "# data_folder = \"/app/data/Transmitter identification/results/plain/20190504_18h30/\"\n",
    "base_log_folder = \"/app/data/Tensorboard/TxId/\"\n",
    "train_record_name = \"train_ds.tfrecords\"\n",
    "val_record_name = \"validation_ds.tfrecords\"\n",
    "test_record_name = \"test_ds.tfrecords\"\n",
    "\n",
    "num_classes = 22\n",
    "learning_rate = 1e-3\n",
    "loss=\"categorical_crossentropy\"\n",
    "batch_size = 2**8\n",
    "num_dense_layers = 6\n",
    "num_conv_layers = 5\n",
    "dense_regularisation = 0.00001\n",
    "epochs = 100\n",
    "\n",
    "pw_decay_bounds_epochs_arr = epochs * np.array([0.03, 0.06, 0.08, 0.1, 0.15, 0.2, 0.35, 0.4, 0.5, 0.6, 0.8, 0.9])\n",
    "pw_decay_values = [1e-5, 2e-5, 4e-5, 8e-5, 1e-4, 2e-4, 5e-4, 1e-3, 1e-3, 1e-3, 1e-4, 5e-5, 1e-5]\n",
    "\n",
    "pipeline_parallel_calls = 20 #tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def find_same_ds_training(data_folder, base_log_folder)-> int:\n",
    "    \"\"\"\n",
    "    Looks at the log folder contents to find howmany trainings have been done on the specified dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_folder : sring\n",
    "        Path to the dataset\n",
    "    base_log_folder : string\n",
    "        Base logging location\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Current number of same ds training (1+number of found trainings)\n",
    "    \"\"\"\n",
    "    \n",
    "    expected_log_path = base_log_folder + data_folder.split('/')[-3] + \"/\" + data_folder.split('/')[-2] # Concatenates base log, type of scenario, and ds date\n",
    "    print(expected_log_path)\n",
    "    matching_files = glob.glob(expected_log_path + \"/*/\")\n",
    "    print(matching_files)\n",
    "    # TODO Could change from counting files to finding the biggest number (in case of missing ones)\n",
    "    return 1 + len(matching_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/data/Tensorboard/TxId/RobotRx/20230602_12h07\n",
      "['/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/019/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/021/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/009/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/013/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/003/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/007/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/006/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/016/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/018/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/020/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/014/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/004/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/015/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/002/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/011/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/010/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/001/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/008/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/005/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/012/', '/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/017/']\n",
      "/app/data/Tensorboard/TxId/RobotRx/20230602_12h07/022\n"
     ]
    }
   ],
   "source": [
    "same_ds_training = find_same_ds_training(data_folder, base_log_folder)\n",
    "\n",
    "save_log_folder = base_log_folder + data_folder.split('/')[-3] + \"/\" + data_folder.split('/')[-2]+f\"/{same_ds_training:03}\"\n",
    "print(save_log_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_06.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_11.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_18.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_00.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_17.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_13.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_14.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_05.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_20.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_21.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_19.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_10.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_04.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_01.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_03.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_08.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_16.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_09.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_12.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_07.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_02.bin', '/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/enreg_re_15.bin']\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Get list of file names for real components.\n",
    "# Expects that there is always a matching im file\n",
    "re_glob = glob.glob(data_folder + \"*re_*.bin\")\n",
    "\n",
    "\n",
    "print(re_glob)\n",
    "file_amount = len(re_glob)\n",
    "print(file_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd16dd5ce45f4e8f82c00a541c7ade6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmplx_list = []\n",
    "tx_id_list = []\n",
    "for file_re in tqdm(re_glob, total=len(re_glob)):\n",
    "    tx_num = int(file_re.split('/')[-1].split('_')[-1][:-4]) #Extract tx id from file name\n",
    "    # rx_num = int(file_re.split('/')[-1].split('_')[-3]) #Extract rx id from file name, may break if it's not provided\n",
    "\n",
    "    # print(f\"File {file_re} read with tx num {tx_num}\")\n",
    "\n",
    "    file_im = file_re.replace(\"re_\", \"im_\")\n",
    "    re = np.fromfile(file_re, dtype=np.float32, count=-1)\n",
    "    im = np.fromfile(file_im, dtype=np.float32, count=-1)\n",
    "    cmplx = re + (1j * im)\n",
    "\n",
    "    if len(cmplx) > 0: # Avoid tripping on empty files\n",
    "        cmplx = cmplx[: (len(cmplx)//600) * 600] # Get integer number of payloads\n",
    "        cmplx = np.reshape(cmplx, (-1, 600))\n",
    "        cmplx_list.append(cmplx)\n",
    "        tx_id_list.append(tx_num * np.ones((cmplx.shape[0], 1), dtype=np.int64))\n",
    "        # print(tx_num * np.ones((cmplx.shape[0], 1), dtype=np.int64))\n",
    "\n",
    "# We have a list of complex matrices (one list element per file), with a tx_number to go with each payload\n",
    "concat_cmplx = np.concatenate(cmplx_list, axis=0)\n",
    "concat_tx_id_list = np.concatenate(tx_id_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 16:51:01.154475: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2415691200 exceeds 10% of free system memory.\n",
      "2023-06-15 16:51:02.639584: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2415691200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503269\n"
     ]
    }
   ],
   "source": [
    "base_ds = tf.data.Dataset.from_tensor_slices((concat_cmplx, concat_tx_id_list))\n",
    "total_packet_num = base_ds.cardinality().numpy()\n",
    "print(total_packet_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "shuffled_ds = base_ds.shuffle(buffer_size=total_packet_num, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packet number in total 503269, train 352288, validation 50326, and test 100653\n"
     ]
    }
   ],
   "source": [
    "train_packet_num = int(0.7 * total_packet_num)\n",
    "val_packet_num = int(0.1 * total_packet_num)\n",
    "test_packet_num = int(0.2 * total_packet_num)\n",
    "print(f\"Packet number in total {total_packet_num}, train {train_packet_num}, validation {val_packet_num}, and test {test_packet_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = shuffled_ds.take(train_packet_num)\n",
    "val_ds = shuffled_ds.skip(train_packet_num).take(val_packet_num)\n",
    "test_ds = shuffled_ds.skip(train_packet_num+val_packet_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True)\n",
    "def input_pipeline_mapping(data, label):\n",
    "    one_hot_lbl = tf.one_hot(label, depth=num_classes, axis=0)\n",
    "    normed_data = tf.math.l2_normalize(data)\n",
    "    split_cmplx = tf.reshape(tf.stack((tf.math.real(normed_data), tf.math.imag(normed_data)), axis=1), (600,2,1))\n",
    "\n",
    "    return split_cmplx, one_hot_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "splitted_train_ds = train_ds.map(input_pipeline_mapping, deterministic=False, num_parallel_calls=pipeline_parallel_calls).shuffle(buffer_size=batch_size*50)\n",
    "splitted_val_ds = val_ds.map(input_pipeline_mapping, deterministic=False, num_parallel_calls=pipeline_parallel_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# one_hot_train_ds = train_ds.map(lambda data, label: (data, tf.one_hot(label, depth=num_classes, axis=0)), deterministic=False, num_parallel_calls=pipeline_parallel_calls)\n",
    "# one_hot_val_ds = val_ds.map(lambda data, label: (data, tf.one_hot(label, depth=num_classes, axis=0)), deterministic=False, num_parallel_calls=pipeline_parallel_calls)\n",
    "\n",
    "# norm_train_ds = one_hot_train_ds.map(lambda data, label: (tf.math.l2_normalize(data), label), deterministic=False, num_parallel_calls=pipeline_parallel_calls)\n",
    "# norm_val_ds = one_hot_val_ds.map(lambda data, label: (tf.math.l2_normalize(data), label), deterministic=False, num_parallel_calls=pipeline_parallel_calls)\n",
    "\n",
    "# splitted_train_ds = norm_train_ds.map(lambda data, label: (tf.reshape(tf.stack((tf.math.real(data), tf.math.imag(data)), axis=1), (600,2,1)), label), deterministic=False, num_parallel_calls=pipeline_parallel_calls)\n",
    "# splitted_val_ds = norm_val_ds.map(lambda data, label: (tf.reshape(tf.stack((tf.math.real(data), tf.math.imag(data)), axis=1), (600,2,1)), label), deterministic=False, num_parallel_calls=pipeline_parallel_calls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def make_model(num_classes=22, num_dense_layers=6, num_conv_layers=5, dense_regularisation=0.000001):\n",
    "    if dense_regularisation > 0:\n",
    "        reg_func = tf.keras.regularizers.l1(dense_regularisation)\n",
    "    else:\n",
    "        reg_func = None\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    for layer in range(num_conv_layers):\n",
    "        if layer==0:\n",
    "            model.add(tf.keras.layers.Conv2D(filters=2**(3+layer), kernel_size=[6, 2], activation='elu'))\n",
    "        else:\n",
    "            model.add(tf.keras.layers.Conv2D(filters=2**(3+layer), kernel_size=[2, 1], activation='elu')) #size 4,1\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=[2, 1], strides=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    for layer in range(num_dense_layers):\n",
    "        model.add(tf.keras.layers.Dense(2**(3+num_dense_layers-layer), activation='elu', kernel_regularizer=reg_func))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax', kernel_regularizer=reg_func))\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def lr_warmup_cosine_decay(global_step,\n",
    "                           warmup_steps,\n",
    "                           hold = 0,\n",
    "                           total_steps=0,\n",
    "                           start_lr=0.0,\n",
    "                           target_lr=1e-3):\n",
    "    # Cosine decay\n",
    "    # There is no tf.pi so we wrap pi as a TF constant\n",
    "    learning_rate = 0.5 * target_lr * (1 + tf.cos(tf.constant(3.1415926535897932384626433) * (global_step - warmup_steps - hold) / float(total_steps - warmup_steps - hold)))\n",
    "\n",
    "    # Target LR * progress of warmup (=1 at the final warmup step)\n",
    "    warmup_lr = target_lr * (global_step / warmup_steps)\n",
    "\n",
    "    # Choose between `warmup_lr`, `target_lr` and `learning_rate` based on whether `global_step < warmup_steps` and we're still holding.\n",
    "    # i.e. warm up if we're still warming up and use cosine decayed lr otherwise\n",
    "    if hold > 0:\n",
    "        learning_rate = tf.where(global_step > warmup_steps + hold,\n",
    "                                 learning_rate, target_lr)\n",
    "    \n",
    "    learning_rate = tf.where(global_step < warmup_steps, warmup_lr, learning_rate)\n",
    "    return learning_rate\n",
    "\n",
    "\n",
    "class WarmUpCosineDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, start_lr, target_lr, warmup_steps, total_steps, hold):\n",
    "        super().__init__()\n",
    "        self.start_lr = start_lr\n",
    "        self.target_lr = target_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.hold = hold\n",
    "\n",
    "    def __call__(self, step):\n",
    "        lr = lr_warmup_cosine_decay(global_step=step,\n",
    "                                    total_steps=self.total_steps,\n",
    "                                    warmup_steps=self.warmup_steps,\n",
    "                                    start_lr=self.start_lr,\n",
    "                                    target_lr=self.target_lr,\n",
    "                                    hold=self.hold)\n",
    "\n",
    "        return tf.where(\n",
    "            step > self.total_steps, 0.0, lr, name=\"learning_rate\"\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 16:51:04.977961: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2415691200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 16:51:06.148689: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [503269,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-06-15 16:51:06.149160: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [503269,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-06-15 16:51:10.032852: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5c180085c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-15 16:51:10.032961: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Host, Default Version\n",
      "2023-06-15 16:51:10.054266: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-15 16:51:10.133650: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-06-15 16:51:10.440113: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x55edd56e8360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-15 16:51:10.440168: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2023-06-15 16:51:10.550564: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator PiecewiseConstant/case/Assert/AssertGuard/Assert\n",
      "2023-06-15 16:51:11.154136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8901\n",
      "2023-06-15 16:51:23.463427: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:38] Ignoring Assert operator PiecewiseConstant/case/Assert/AssertGuard/Assert\n",
      "2023-06-15 16:51:26.982038: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2415691200 exceeds 10% of free system memory.\n",
      "2023-06-15 16:51:28.356576: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype complex64 and shape [503269,600]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-15 16:51:28.357046: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [503269,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377/1377 - 27s - loss: 3.4026 - categorical_accuracy: 0.0484 - val_loss: 3.3730 - val_categorical_accuracy: 0.0587 - 27s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "1377/1377 - 12s - loss: 3.3476 - categorical_accuracy: 0.0592 - val_loss: 3.3258 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 3/100\n",
      "1377/1377 - 13s - loss: 3.3047 - categorical_accuracy: 0.0592 - val_loss: 3.2871 - val_categorical_accuracy: 0.0587 - 13s/epoch - 9ms/step\n",
      "Epoch 4/100\n",
      "1377/1377 - 13s - loss: 3.2558 - categorical_accuracy: 0.0589 - val_loss: 3.2305 - val_categorical_accuracy: 0.0587 - 13s/epoch - 9ms/step\n",
      "Epoch 5/100\n",
      "1377/1377 - 12s - loss: 3.2102 - categorical_accuracy: 0.0587 - val_loss: 3.1943 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 6/100\n",
      "1377/1377 - 12s - loss: 3.1797 - categorical_accuracy: 0.0588 - val_loss: 3.1686 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 7/100\n",
      "1377/1377 - 12s - loss: 3.1501 - categorical_accuracy: 0.0581 - val_loss: 3.1362 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 8/100\n",
      "1377/1377 - 13s - loss: 3.1249 - categorical_accuracy: 0.0589 - val_loss: 3.1181 - val_categorical_accuracy: 0.0556 - 13s/epoch - 9ms/step\n",
      "Epoch 9/100\n",
      "1377/1377 - 12s - loss: 3.1057 - categorical_accuracy: 0.0583 - val_loss: 3.0985 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 10/100\n",
      "1377/1377 - 12s - loss: 3.0916 - categorical_accuracy: 0.0587 - val_loss: 3.0880 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 11/100\n",
      "1377/1377 - 12s - loss: 3.0824 - categorical_accuracy: 0.0589 - val_loss: 3.0796 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 12/100\n",
      "1377/1377 - 12s - loss: 3.0759 - categorical_accuracy: 0.0584 - val_loss: 3.0748 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 13/100\n",
      "1377/1377 - 12s - loss: 3.0718 - categorical_accuracy: 0.0590 - val_loss: 3.0714 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 14/100\n",
      "1377/1377 - 12s - loss: 3.0688 - categorical_accuracy: 0.0591 - val_loss: 3.0687 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 15/100\n",
      "1377/1377 - 12s - loss: 3.0666 - categorical_accuracy: 0.0591 - val_loss: 3.0672 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 16/100\n",
      "1377/1377 - 12s - loss: 3.0646 - categorical_accuracy: 0.0586 - val_loss: 3.0646 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 17/100\n",
      "1377/1377 - 12s - loss: 3.0627 - categorical_accuracy: 0.0589 - val_loss: 3.0631 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 18/100\n",
      "1377/1377 - 12s - loss: 3.0613 - categorical_accuracy: 0.0590 - val_loss: 3.0621 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "1377/1377 - 12s - loss: 3.0603 - categorical_accuracy: 0.0590 - val_loss: 3.0613 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "1377/1377 - 12s - loss: 3.0596 - categorical_accuracy: 0.0590 - val_loss: 3.0611 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 21/100\n",
      "1377/1377 - 13s - loss: 3.0595 - categorical_accuracy: 0.0583 - val_loss: 3.0602 - val_categorical_accuracy: 0.0587 - 13s/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "1377/1377 - 13s - loss: 3.0588 - categorical_accuracy: 0.0588 - val_loss: 3.0597 - val_categorical_accuracy: 0.0587 - 13s/epoch - 9ms/step\n",
      "Epoch 23/100\n",
      "1377/1377 - 12s - loss: 3.0581 - categorical_accuracy: 0.0588 - val_loss: 3.0591 - val_categorical_accuracy: 0.0587 - 12s/epoch - 9ms/step\n",
      "Epoch 24/100\n",
      "1377/1377 - 12s - loss: 2.0939 - categorical_accuracy: 0.2882 - val_loss: 1.4716 - val_categorical_accuracy: 0.4436 - 12s/epoch - 9ms/step\n",
      "Epoch 25/100\n",
      "1377/1377 - 12s - loss: 1.3523 - categorical_accuracy: 0.4854 - val_loss: 1.3767 - val_categorical_accuracy: 0.4752 - 12s/epoch - 9ms/step\n",
      "Epoch 26/100\n",
      "1377/1377 - 12s - loss: 1.2941 - categorical_accuracy: 0.5055 - val_loss: 1.3354 - val_categorical_accuracy: 0.4936 - 12s/epoch - 9ms/step\n",
      "Epoch 27/100\n",
      "1377/1377 - 12s - loss: 1.2643 - categorical_accuracy: 0.5174 - val_loss: 1.4580 - val_categorical_accuracy: 0.4393 - 12s/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "1377/1377 - 12s - loss: 1.2475 - categorical_accuracy: 0.5229 - val_loss: 1.2838 - val_categorical_accuracy: 0.5046 - 12s/epoch - 9ms/step\n",
      "Epoch 29/100\n",
      "1377/1377 - 12s - loss: 1.2368 - categorical_accuracy: 0.5270 - val_loss: 1.2400 - val_categorical_accuracy: 0.5218 - 12s/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "1377/1377 - 12s - loss: 1.2199 - categorical_accuracy: 0.5322 - val_loss: 1.3205 - val_categorical_accuracy: 0.4895 - 12s/epoch - 9ms/step\n",
      "Epoch 31/100\n",
      "1377/1377 - 12s - loss: 1.2162 - categorical_accuracy: 0.5332 - val_loss: 1.2310 - val_categorical_accuracy: 0.5205 - 12s/epoch - 9ms/step\n",
      "Epoch 32/100\n",
      "1377/1377 - 12s - loss: 1.2030 - categorical_accuracy: 0.5380 - val_loss: 1.1926 - val_categorical_accuracy: 0.5447 - 12s/epoch - 9ms/step\n",
      "Epoch 33/100\n",
      "1377/1377 - 13s - loss: 1.1967 - categorical_accuracy: 0.5398 - val_loss: 1.2700 - val_categorical_accuracy: 0.5039 - 13s/epoch - 9ms/step\n",
      "Epoch 34/100\n",
      "1377/1377 - 12s - loss: 1.1916 - categorical_accuracy: 0.5419 - val_loss: 1.2020 - val_categorical_accuracy: 0.5376 - 12s/epoch - 9ms/step\n",
      "Epoch 35/100\n",
      "1377/1377 - 13s - loss: 1.1853 - categorical_accuracy: 0.5432 - val_loss: 1.3497 - val_categorical_accuracy: 0.4774 - 13s/epoch - 9ms/step\n",
      "Epoch 36/100\n",
      "1377/1377 - 12s - loss: 1.2318 - categorical_accuracy: 0.5245 - val_loss: 1.2744 - val_categorical_accuracy: 0.5082 - 12s/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "1377/1377 - 12s - loss: 1.2166 - categorical_accuracy: 0.5297 - val_loss: 1.2221 - val_categorical_accuracy: 0.5349 - 12s/epoch - 9ms/step\n",
      "Epoch 38/100\n",
      "1377/1377 - 12s - loss: 1.2112 - categorical_accuracy: 0.5321 - val_loss: 1.2752 - val_categorical_accuracy: 0.5044 - 12s/epoch - 9ms/step\n",
      "Epoch 39/100\n",
      "1377/1377 - 13s - loss: 1.1990 - categorical_accuracy: 0.5366 - val_loss: 1.3034 - val_categorical_accuracy: 0.4830 - 13s/epoch - 9ms/step\n",
      "Epoch 40/100\n",
      "1377/1377 - 12s - loss: 1.1892 - categorical_accuracy: 0.5411 - val_loss: 1.3360 - val_categorical_accuracy: 0.4894 - 12s/epoch - 9ms/step\n",
      "Epoch 41/100\n",
      "1377/1377 - 13s - loss: 1.1860 - categorical_accuracy: 0.5415 - val_loss: 1.1986 - val_categorical_accuracy: 0.5325 - 13s/epoch - 9ms/step\n",
      "Epoch 42/100\n",
      "1377/1377 - 12s - loss: 1.1773 - categorical_accuracy: 0.5441 - val_loss: 1.2156 - val_categorical_accuracy: 0.5281 - 12s/epoch - 9ms/step\n",
      "Epoch 43/100\n",
      "1377/1377 - 12s - loss: 1.1769 - categorical_accuracy: 0.5450 - val_loss: 1.3276 - val_categorical_accuracy: 0.4914 - 12s/epoch - 9ms/step\n",
      "Epoch 44/100\n",
      "1377/1377 - 12s - loss: 1.1712 - categorical_accuracy: 0.5471 - val_loss: 1.1758 - val_categorical_accuracy: 0.5434 - 12s/epoch - 9ms/step\n",
      "Epoch 45/100\n",
      "1377/1377 - 12s - loss: 1.1667 - categorical_accuracy: 0.5480 - val_loss: 1.1711 - val_categorical_accuracy: 0.5485 - 12s/epoch - 9ms/step\n",
      "Epoch 46/100\n",
      "1377/1377 - 12s - loss: 1.1590 - categorical_accuracy: 0.5517 - val_loss: 1.1591 - val_categorical_accuracy: 0.5525 - 12s/epoch - 9ms/step\n",
      "Epoch 47/100\n",
      "1377/1377 - 13s - loss: 1.1571 - categorical_accuracy: 0.5520 - val_loss: 1.2132 - val_categorical_accuracy: 0.5300 - 13s/epoch - 9ms/step\n",
      "Epoch 48/100\n",
      "1377/1377 - 12s - loss: 1.1449 - categorical_accuracy: 0.5559 - val_loss: 1.1843 - val_categorical_accuracy: 0.5393 - 12s/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "1377/1377 - 13s - loss: 1.1452 - categorical_accuracy: 0.5562 - val_loss: 1.2926 - val_categorical_accuracy: 0.4995 - 13s/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "1377/1377 - 12s - loss: 1.1433 - categorical_accuracy: 0.5563 - val_loss: 1.2077 - val_categorical_accuracy: 0.5329 - 12s/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "1377/1377 - 13s - loss: 1.1309 - categorical_accuracy: 0.5617 - val_loss: 1.1578 - val_categorical_accuracy: 0.5515 - 13s/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "1377/1377 - 13s - loss: 1.1235 - categorical_accuracy: 0.5641 - val_loss: 1.1163 - val_categorical_accuracy: 0.5714 - 13s/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "1377/1377 - 12s - loss: 1.1197 - categorical_accuracy: 0.5661 - val_loss: 1.1951 - val_categorical_accuracy: 0.5370 - 12s/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "1377/1377 - 12s - loss: 1.1214 - categorical_accuracy: 0.5647 - val_loss: 1.1758 - val_categorical_accuracy: 0.5410 - 12s/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "1377/1377 - 13s - loss: 1.1146 - categorical_accuracy: 0.5691 - val_loss: 1.1103 - val_categorical_accuracy: 0.5712 - 13s/epoch - 9ms/step\n",
      "Epoch 56/100\n",
      "1377/1377 - 12s - loss: 1.1029 - categorical_accuracy: 0.5754 - val_loss: 1.1200 - val_categorical_accuracy: 0.5689 - 12s/epoch - 9ms/step\n",
      "Epoch 57/100\n",
      "1377/1377 - 13s - loss: 1.0886 - categorical_accuracy: 0.5830 - val_loss: 1.2245 - val_categorical_accuracy: 0.5239 - 13s/epoch - 9ms/step\n",
      "Epoch 58/100\n",
      "1377/1377 - 12s - loss: 1.0723 - categorical_accuracy: 0.5905 - val_loss: 1.1883 - val_categorical_accuracy: 0.5479 - 12s/epoch - 9ms/step\n",
      "Epoch 59/100\n",
      "1377/1377 - 14s - loss: 1.0611 - categorical_accuracy: 0.5951 - val_loss: 1.1112 - val_categorical_accuracy: 0.5674 - 14s/epoch - 10ms/step\n",
      "Epoch 60/100\n",
      "1377/1377 - 13s - loss: 1.0481 - categorical_accuracy: 0.6016 - val_loss: 0.9872 - val_categorical_accuracy: 0.6289 - 13s/epoch - 10ms/step\n",
      "Epoch 61/100\n",
      "1377/1377 - 13s - loss: 0.9609 - categorical_accuracy: 0.6369 - val_loss: 0.9777 - val_categorical_accuracy: 0.6311 - 13s/epoch - 9ms/step\n",
      "Epoch 62/100\n",
      "1377/1377 - 12s - loss: 0.9551 - categorical_accuracy: 0.6387 - val_loss: 0.9657 - val_categorical_accuracy: 0.6361 - 12s/epoch - 9ms/step\n",
      "Epoch 63/100\n",
      "1377/1377 - 13s - loss: 0.9528 - categorical_accuracy: 0.6393 - val_loss: 0.9708 - val_categorical_accuracy: 0.6339 - 13s/epoch - 10ms/step\n",
      "Epoch 64/100\n",
      "1377/1377 - 13s - loss: 0.9504 - categorical_accuracy: 0.6404 - val_loss: 0.9657 - val_categorical_accuracy: 0.6366 - 13s/epoch - 10ms/step\n",
      "Epoch 65/100\n",
      "1377/1377 - 13s - loss: 0.9483 - categorical_accuracy: 0.6415 - val_loss: 0.9616 - val_categorical_accuracy: 0.6383 - 13s/epoch - 10ms/step\n",
      "Epoch 66/100\n",
      "1377/1377 - 13s - loss: 0.9464 - categorical_accuracy: 0.6413 - val_loss: 0.9621 - val_categorical_accuracy: 0.6374 - 13s/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "1377/1377 - 13s - loss: 0.9443 - categorical_accuracy: 0.6425 - val_loss: 0.9706 - val_categorical_accuracy: 0.6329 - 13s/epoch - 10ms/step\n",
      "Epoch 68/100\n",
      "1377/1377 - 13s - loss: 0.9425 - categorical_accuracy: 0.6433 - val_loss: 0.9569 - val_categorical_accuracy: 0.6400 - 13s/epoch - 10ms/step\n",
      "Epoch 69/100\n",
      "1377/1377 - 13s - loss: 0.9421 - categorical_accuracy: 0.6436 - val_loss: 0.9589 - val_categorical_accuracy: 0.6383 - 13s/epoch - 10ms/step\n",
      "Epoch 70/100\n",
      "1377/1377 - 14s - loss: 0.9397 - categorical_accuracy: 0.6445 - val_loss: 0.9609 - val_categorical_accuracy: 0.6374 - 14s/epoch - 10ms/step\n",
      "Epoch 71/100\n",
      "1377/1377 - 14s - loss: 0.9389 - categorical_accuracy: 0.6447 - val_loss: 0.9527 - val_categorical_accuracy: 0.6409 - 14s/epoch - 10ms/step\n",
      "Epoch 72/100\n",
      "1377/1377 - 14s - loss: 0.9373 - categorical_accuracy: 0.6449 - val_loss: 0.9569 - val_categorical_accuracy: 0.6391 - 14s/epoch - 10ms/step\n",
      "Epoch 73/100\n",
      "1377/1377 - 13s - loss: 0.9363 - categorical_accuracy: 0.6455 - val_loss: 0.9505 - val_categorical_accuracy: 0.6409 - 13s/epoch - 9ms/step\n",
      "Epoch 74/100\n",
      "1377/1377 - 12s - loss: 0.9340 - categorical_accuracy: 0.6464 - val_loss: 0.9545 - val_categorical_accuracy: 0.6402 - 12s/epoch - 9ms/step\n",
      "Epoch 75/100\n",
      "1377/1377 - 12s - loss: 0.9330 - categorical_accuracy: 0.6470 - val_loss: 0.9530 - val_categorical_accuracy: 0.6392 - 12s/epoch - 9ms/step\n",
      "Epoch 76/100\n",
      "1377/1377 - 13s - loss: 0.9315 - categorical_accuracy: 0.6474 - val_loss: 0.9613 - val_categorical_accuracy: 0.6380 - 13s/epoch - 9ms/step\n",
      "Epoch 77/100\n",
      "1377/1377 - 12s - loss: 0.9309 - categorical_accuracy: 0.6482 - val_loss: 0.9442 - val_categorical_accuracy: 0.6451 - 12s/epoch - 9ms/step\n",
      "Epoch 78/100\n",
      "1377/1377 - 13s - loss: 0.9287 - categorical_accuracy: 0.6487 - val_loss: 0.9456 - val_categorical_accuracy: 0.6434 - 13s/epoch - 9ms/step\n",
      "Epoch 79/100\n",
      "1377/1377 - 12s - loss: 0.9277 - categorical_accuracy: 0.6484 - val_loss: 0.9459 - val_categorical_accuracy: 0.6435 - 12s/epoch - 9ms/step\n",
      "Epoch 80/100\n",
      "1377/1377 - 12s - loss: 0.9265 - categorical_accuracy: 0.6493 - val_loss: 0.9378 - val_categorical_accuracy: 0.6464 - 12s/epoch - 9ms/step\n",
      "Epoch 81/100\n",
      "1377/1377 - 13s - loss: 0.9185 - categorical_accuracy: 0.6532 - val_loss: 0.9357 - val_categorical_accuracy: 0.6473 - 13s/epoch - 9ms/step\n",
      "Epoch 82/100\n",
      "1377/1377 - 13s - loss: 0.9177 - categorical_accuracy: 0.6539 - val_loss: 0.9358 - val_categorical_accuracy: 0.6477 - 13s/epoch - 9ms/step\n",
      "Epoch 83/100\n",
      "1377/1377 - 13s - loss: 0.9174 - categorical_accuracy: 0.6534 - val_loss: 0.9349 - val_categorical_accuracy: 0.6486 - 13s/epoch - 9ms/step\n",
      "Epoch 84/100\n",
      "1377/1377 - 14s - loss: 0.9164 - categorical_accuracy: 0.6544 - val_loss: 0.9365 - val_categorical_accuracy: 0.6481 - 14s/epoch - 10ms/step\n",
      "Epoch 85/100\n",
      "1377/1377 - 13s - loss: 0.9155 - categorical_accuracy: 0.6542 - val_loss: 0.9362 - val_categorical_accuracy: 0.6475 - 13s/epoch - 9ms/step\n",
      "Epoch 86/100\n",
      "1377/1377 - 14s - loss: 0.9148 - categorical_accuracy: 0.6550 - val_loss: 0.9320 - val_categorical_accuracy: 0.6487 - 14s/epoch - 10ms/step\n",
      "Epoch 87/100\n",
      "1377/1377 - 13s - loss: 0.9148 - categorical_accuracy: 0.6547 - val_loss: 0.9357 - val_categorical_accuracy: 0.6482 - 13s/epoch - 10ms/step\n",
      "Epoch 88/100\n",
      "1377/1377 - 13s - loss: 0.9135 - categorical_accuracy: 0.6551 - val_loss: 0.9333 - val_categorical_accuracy: 0.6464 - 13s/epoch - 10ms/step\n",
      "Epoch 89/100\n",
      "1377/1377 - 14s - loss: 0.9127 - categorical_accuracy: 0.6558 - val_loss: 0.9334 - val_categorical_accuracy: 0.6485 - 14s/epoch - 10ms/step\n",
      "Epoch 90/100\n",
      "1377/1377 - 14s - loss: 0.9122 - categorical_accuracy: 0.6553 - val_loss: 0.9264 - val_categorical_accuracy: 0.6513 - 14s/epoch - 10ms/step\n",
      "Epoch 91/100\n",
      "1377/1377 - 14s - loss: 0.9055 - categorical_accuracy: 0.6586 - val_loss: 0.9274 - val_categorical_accuracy: 0.6516 - 14s/epoch - 10ms/step\n",
      "Epoch 92/100\n",
      "1377/1377 - 14s - loss: 0.9051 - categorical_accuracy: 0.6587 - val_loss: 0.9252 - val_categorical_accuracy: 0.6521 - 14s/epoch - 10ms/step\n",
      "Epoch 93/100\n",
      "1377/1377 - 15s - loss: 0.9050 - categorical_accuracy: 0.6588 - val_loss: 0.9250 - val_categorical_accuracy: 0.6520 - 15s/epoch - 11ms/step\n",
      "Epoch 94/100\n",
      "1377/1377 - 15s - loss: 0.9048 - categorical_accuracy: 0.6590 - val_loss: 0.9244 - val_categorical_accuracy: 0.6523 - 15s/epoch - 11ms/step\n",
      "Epoch 95/100\n",
      "1377/1377 - 14s - loss: 0.9047 - categorical_accuracy: 0.6589 - val_loss: 0.9248 - val_categorical_accuracy: 0.6516 - 14s/epoch - 10ms/step\n",
      "Epoch 96/100\n",
      "1377/1377 - 14s - loss: 0.9046 - categorical_accuracy: 0.6590 - val_loss: 0.9247 - val_categorical_accuracy: 0.6520 - 14s/epoch - 10ms/step\n",
      "Epoch 97/100\n",
      "1377/1377 - 15s - loss: 0.9043 - categorical_accuracy: 0.6592 - val_loss: 0.9240 - val_categorical_accuracy: 0.6520 - 15s/epoch - 11ms/step\n",
      "Epoch 98/100\n",
      "1377/1377 - 14s - loss: 0.9041 - categorical_accuracy: 0.6590 - val_loss: 0.9236 - val_categorical_accuracy: 0.6533 - 14s/epoch - 10ms/step\n",
      "Epoch 99/100\n",
      "1377/1377 - 14s - loss: 0.9040 - categorical_accuracy: 0.6594 - val_loss: 0.9246 - val_categorical_accuracy: 0.6528 - 14s/epoch - 10ms/step\n",
      "Epoch 100/100\n",
      "1377/1377 - 14s - loss: 0.9038 - categorical_accuracy: 0.6594 - val_loss: 0.9238 - val_categorical_accuracy: 0.6524 - 14s/epoch - 10ms/step\n"
     ]
    }
   ],
   "source": [
    "model = make_model(num_classes=num_classes, num_conv_layers=num_conv_layers, num_dense_layers=num_dense_layers, dense_regularisation=dense_regularisation)\n",
    "# scheduler = tf.keras.optimizers.schedules.CosineDecayRestarts(learning_rate, first_decay_steps=25*(train_packet_num/batch_size), alpha=0.0001, t_mul=2, m_mul=0.5)\n",
    "# scheduler = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, decay_steps=(epochs/2)*(train_packet_num/batch_size), decay_rate=0.1)\n",
    "# scheduler = tf.keras.optimizers.schedules.PiecewiseConstantDecay(list(pw_decay_bounds_epochs_arr*(train_packet_num/batch_size)), values=pw_decay_values)\n",
    "scheduler = WarmUpCosineDecay(start_lr=0.0, target_lr=learning_rate, warmup_steps=10*(train_packet_num/batch_size), total_steps=epochs*(train_packet_num/batch_size), hold=0)\n",
    "# model.compile(optimizer=tf.optimizers.Adam(learning_rate), loss=loss, metrics=['categorical_accuracy'], jit_compile=True,)\n",
    "model.compile(optimizer=tf.optimizers.Adam(scheduler), loss=loss, metrics=['categorical_accuracy'], jit_compile=True,)\n",
    "\n",
    "callbacks = [\n",
    "            # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "        #                               tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss', min_delta=0.001),\n",
    "            # Write TensorBoard logs to `./logs` directory\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=save_log_folder,\n",
    "                                           write_graph=False,\n",
    "                                           update_freq='epoch',\n",
    "                                           write_steps_per_second=True,\n",
    "                                        #    histogram_freq=1,\n",
    "                                        #    profile_batch=(100,120),\n",
    "                                           )\n",
    "        ]\n",
    "\n",
    "history = model.fit(splitted_train_ds.batch(batch_size).prefetch(5), epochs=100,\n",
    "            callbacks=callbacks, verbose = 2,\n",
    "            validation_data=splitted_val_ds.batch(batch_size).prefetch(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f\"{data_folder}weights/Conv_num={num_conv_layers}_Dens_num={num_dense_layers}_softmax_lr={learning_rate}_batch={batch_size}_regl1={dense_regularisation}_{same_ds_training:03}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On set perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_test_ds = test_ds.map(lambda data, label: (data, tf.one_hot(label, depth=num_classes, axis=0)), deterministic=False, num_parallel_calls=pipeline_parallel_calls)\n",
    "\n",
    "norm_test_ds = one_hot_test_ds.map(lambda data, label: (tf.math.l2_normalize(data), label), deterministic=False, num_parallel_calls=pipeline_parallel_calls)\n",
    "\n",
    "splitted_test_ds = norm_test_ds.map(lambda data, label: (tf.reshape(tf.stack((tf.math.real(data), tf.math.imag(data)), axis=1), (600,2,1)), label), deterministic=False, num_parallel_calls=pipeline_parallel_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'categorical_accuracy']\n",
      "/app/local_home/cmorin/Tx-Id/datasets/RobotRx/20230602_12h07/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 14:14:54.608618: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2415691200 exceeds 10% of free system memory.\n",
      "2023-06-15 14:14:55.161342: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [503269,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-06-15 14:14:55.161803: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [503269,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 7s 65ms/step - loss: 0.9322 - categorical_accuracy: 0.6429\n",
      "[0.9322349429130554, 0.6429486870765686]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(data_folder)\n",
    "print(model.evaluate(splitted_test_ds.batch(2048)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size = 22\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          normalize=True,\n",
    "                          classes=size,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.colorbar(shrink = 0.78)\n",
    "    tick_marks = range(classes)\n",
    "    plt.xticks(tick_marks, range(0, classes + 0))\n",
    "    plt.yticks(tick_marks, range(0, classes + 0))\n",
    "\n",
    "    if normalize:\n",
    "        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 2)\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    summ=0\n",
    "    thresh = 0.3#cm.max() / 20.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        if i==j:\n",
    "            if cm[i, j] == cm[i, j]:\n",
    "                summ = summ+cm[i, j]\n",
    "#     print(summ)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "#     plt.show()\n",
    "    return(summ)\n",
    "\n",
    "def plot_accuracies(cm, normalize=True, title=\"True positives \"):\n",
    "    if normalize:\n",
    "        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 2)\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    classes = np.minimum(len(cm), len(cm[0]))\n",
    "    plt.ylim(0,1)\n",
    "    plt.xticks(range(classes), range(0, classes + 0))\n",
    "    tp = np.zeros((classes))\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if i==j:\n",
    "            if not np.isnan(cm[i, j]):\n",
    "                tp[i] = cm[i, j]\n",
    "    plt.title(title)\n",
    "    plt.plot(tp)\n",
    "    plt.show()\n",
    "    \n",
    "def print_matrix(cm):\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            strin = \"\"\n",
    "            for k in range (cm.shape[2]):\n",
    "                strin = strin + \" {:03.2f}\".format(cm[i,j,k])\n",
    "            print(strin)\n",
    "        print(\"\")\n",
    "\n",
    "def acc_stats(cm, normalize=True):\n",
    "    if normalize:\n",
    "        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 2)\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    tp = np.zeros((size)) \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if i==j:\n",
    "#             if not np.isnan(cm[i, j]):\n",
    "            tp[j] = cm[i, j]\n",
    "#     print(cm)\n",
    "    return tp\n",
    "                \n",
    "def plot_acc_stats(cm, normalize=True, title=\"True positives \"):\n",
    "#     print(cm)\n",
    "    classes = np.minimum(len(cm[0]), len(cm[0,0]))\n",
    "    tp = np.zeros((5,classes))\n",
    "    tp[1] = np.ones((classes))\n",
    "#     print(tp)\n",
    "    diag_values = np.zeros((classes,classes))\n",
    "    for i in range(len(cm)):\n",
    "        diag_values[i] = acc_stats(cm[i])\n",
    "#     print(diag_values)\n",
    "    tp[0] = np.nanmean(diag_values, axis=0)\n",
    "    tp[1] = np.nanmin(diag_values, axis=0)\n",
    "    tp[2] = np.nanmax(diag_values, axis=0)\n",
    "    tp[3] = np.nanstd(diag_values, axis=0)\n",
    "    tp[4] = np.nanmedian(diag_values, axis=0)\n",
    "#     for j in range(len(tmp)):\n",
    "#         if not np.isnan(tmp[j]):\n",
    "#             tp[0,j] = tp[0,j] + (tmp[j] / (classes-1))\n",
    "\n",
    "\n",
    "        \n",
    "    print(tp)    \n",
    "#     print_matrix(cm)\n",
    "    \n",
    "    plt.ylim(0,1)\n",
    "    plt.xticks(range(classes), range(0, classes + 0))\n",
    "\n",
    "    print(tp)\n",
    "    plt.title(title)\n",
    "    plt.plot(tp[0])\n",
    "    plt.plot(tp[1])\n",
    "    plt.plot(tp[2])\n",
    "    plt.plot(tp[0]+tp[3])\n",
    "    plt.plot(tp[0]-tp[3])\n",
    "    plt.plot(tp[4])\n",
    "    plt.show()\n",
    "    \n",
    "rez = model.evaluate(splitted_test_ds.batch(2048))\n",
    "print(rez)\n",
    "pred = model.predict(splitted_test_ds.batch(2048))\n",
    "# Conversion de One Hot vers standard 0-20\n",
    "\n",
    "def toLabelValue(y):\n",
    "    y_std = np.zeros(len(y), dtype=np.int)\n",
    "    for i in range(len(y)):\n",
    "        y_std[i] = np.argmax(y[i])\n",
    "    return y_std\n",
    "\n",
    "\n",
    "pred_noh = toLabelValue(pred)\n",
    "\n",
    "def confusionMatrix(prediction, label):\n",
    "    # Prediction et label doivent avoir la même taille !\n",
    "    matrix = np.zeros((size,size,size),dtype=np.int)\n",
    "    i = 0\n",
    "    while i < len(label):\n",
    "        matrix[label[i][1]][label[i][0]][prediction[i]] += 1\n",
    "        i += 1\n",
    "    return matrix\n",
    "\n",
    "matrice = confusionMatrix(pred_noh,Y_test_noh)\n",
    "\n",
    "results = np.zeros((1))\n",
    "\n",
    "for i in range(1): \n",
    "    results[i] = plot_confusion_matrix(matrice[i], normalize=True, classes=size)\n",
    "print(results)\n",
    "\n",
    "print(pred_noh.shape,Y_test_noh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 14:27:11.294177: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [1072437,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-06-13 14:27:11.294964: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [1072437,1]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 16s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = model.predict(splitted_test_ds.batch(2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for elem in pred\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
